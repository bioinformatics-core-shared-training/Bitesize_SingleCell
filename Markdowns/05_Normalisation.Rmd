---
title: "Introduction to single-cell RNA-seq analysis"
author: "Stephane Ballereau/ Kamal Kishore"
subtitle: Normalisation - Caron data set - 500 cells per sample
output:
  html_document:
    df_print: paged
    toc: yes
    number_sections: yes
    code_folding: hide
  html_notebook:
    code_folding: hide
    toc: yes
    toc_float: yes
    number_sections: yes
  pdf_document:
    toc: yes
---

# Normalisation - Caron set {#NormalisationCaron5hcpsTop}

```{r norm_Caron.knitr_options, echo=FALSE, results="hide", message=FALSE}
library(knitr)

opts_chunk$set(error=FALSE, message=FALSE, warning=FALSE, cache=FALSE)
opts_chunk$set(fig.width=7, fig.height=7)
set.seed(123) # for reproducibility
```

Sources: chapters on normalisation in the
[OSCA book](http://bioconductor.org/books/3.14/OSCA.basic/normalization.html) and the
[Hemberg group materials](https://scrnaseq-course.cog.sanger.ac.uk/website/index.html).

## Learning objectives

* Understand why normalisation is required
* Understand concepts of deconvolution normalisation method

<!--
* Understand why normalisation is required
  * differences in sequencing coverage between libraries
    * due to low input material, differences in cDNA capture and PCR amplification
  * differences between cells could be technical, not biological
  * comparisons between cells would not be meaningful
* deconvolution
  * compute for each cell a series of cell-pool-based scaling factors
  * to derive one
-->

## Why normalise?

Systematic differences in sequencing coverage between libraries occur because of
low input material, differences in cDNA capture and PCR amplification.
Normalisation removes such differences so that differences between cells are not
technical but biological, allowing meaningful comparison of expression profiles
between cells. 

<!-- PARAMS and LIBRARIES -->

```{r Caron_libraries_norm, results='hide', message=FALSE, warning=FALSE}
library(scater)
library(scran)
library(scuttle)
library(tidyverse)
library(BiocSingular)
library(BiocParallel)
library(glue)
library(patchwork)

# prepare 'cluster' for multicore processing
# use 7 workers
bpp <- MulticoreParam(7)
```

## Load object

We will load the R object created after QC and check its content (class, dimensions, assays, ...)

```{r Caron_norm_readIn_5hCellPerSpl}
# Read object in:
sce <- readRDS("../Robjects/Caron_filtered_genes.rds")
sce
```

```{r}
# rename column(s) if need be
# we need 'SampleName'
dd <- colData(sce) %>%
  data.frame() %>%
  rename(SampleName=Sample) %>%
  DataFrame()

colData(sce) <- dd 

## add SampleGroup information
colData(sce)$SampleGroup <- str_replace(colData(sce)$SampleName,"_.*","")
```

We can also count the number of cells for each sample:

```{r Caron_norm_sampleSheet}
colData(sce) %>%
  # colData() returns a DFrame
  # that we need to convert to a data.frame for parsing
  data.frame() %>%
  # group by some columns only: SampleName, SampleId, SampleGroup
  # (could do with SampleName only but we would miss SampleId, SampleGroup later)
  group_by(SampleName, SampleId, SampleGroup) %>%
  # count cells for each group
  summarise(nbCells=n()) %>%
  # display output table
  DT::datatable(rownames = FALSE,
                options = list(dom="tpl", pageLength = 15))
```

For analyses to run within the time allocated to sessions,
we will subsample cells down to 500 per sample:

```{r Caron_norm_downsample, eval=FALSE}
# number of cells to keep
nbCells <- 500

# have new list of cell barcodes for each sample
vec.bc <- colData(sce) %>%
	data.frame() %>%
	dplyr::filter(!SampleId == "SRR9264351") %>%
	group_by(SampleName) %>%
	sample_n(nbCells) %>%
	pull(Barcode)
```

```{r}
# subsetting a SCE (SingleCellExperiment) object requires indices not names
# so find index for each cell we will keep:
tmpInd <- which(colData(sce)$Barcode %in% vec.bc) # mind QC metrics will be wrong
# subset cells from the existing SCE object:
sce <- sce[,tmpInd] # this update 'sce', e.g. its assays, but not the cell meta data.

colData(sce) %>%
  data.frame() %>%
  dplyr::select(SampleName, SampleId, SampleGroup) %>%
  group_by(SampleName, SampleId, SampleGroup) %>%
  summarise(nbCells=n()) %>%
  DT::datatable(rownames = FALSE,
                options = list(dom="tpl", pageLength = 15, nrows=20))
```

Update per-gene QC metrics.

<!--
# mind that genes were filtered using all cells, not just those sampled here.
# check for lowly expressed genes:
-->

```{r Caron_norm_filterGenes}
# for each gene in each cell: is it expressed?
exprLogic <- counts(sce) > 0
# count cells where gene is expressed,
# and ask if the number of cells is gt 5
detectedGenes <- rowSums(exprLogic) > 5
# count genes in each class, not-detected and detected
table(detectedGenes)

# remove these genes:
sce <- sce[detectedGenes,] # removes genes but does not update QC metrics.

# update cell QC metrics
sce$sum <- NULL
sce$detected <- NULL
sce$total <- NULL
sce <- addPerCellQC(sce)

# update gene QC metrics
sce <- addPerFeatureQC(sce, BPPARAM = bpp)
```

We write the R object to 'caron_filtered_5hCell.Rds'.

```{r Caron_downsample_write, eval=FALSE}
# Write object to file
saveRDS(sce, "../Robjects/caron_filtered_5hCell.Rds")
```

## Scaling normalization

In scaling normalization, the “normalization factor” is an estimate of the
library size relative to the other cells. Steps usually include: computation of
a cell-specific 'scaling' or 'size' factor that represents the relative bias in
that cell and division of all counts for the cell by that factor to remove that
bias. Assumption: any cell specific bias will affect genes the same way.


### Library size normalization

For each cell, the library size factor is proportional to the library size such
that the average size factor across cell is one.

Compute size factors:

```{r librarySizeFactors_comp_norm_Caron_5hCellPerSpl}
lib.sf <- librarySizeFactors(sce)
summary(lib.sf)
```

Size factor distribution: wide range, typical of scRNA-seq data.

```{r librarySizeFactors_hist_norm_Caron_5hCellPerSpl}
dd <- data.frame("log10libSf"=log10(lib.sf))
ggplot(dd, aes(x=log10libSf)) + 
  geom_histogram(bins=50)
```

Assumption: absence of compositional bias; differential expression between two 
cells is balanced: upregulation in some genes is accompanied by downregulation 
of other genes.

This normalisation due to unaccounted-for composition bias affects the 
size of the log fold change measured between clusters, but less so the
clustering itself. It is thus sufficient to identify clusters and top marker 
genes.

### Deconvolution

Composition bias occurs when differential expression between two samples
or here cells is not balanced. For a fixed library size, identical in both cells,
upregulation of one gene in a cell will means fewer UMIs can be assigned to other
genes, which would then appear down regulated. Even if library sizes are allowed
to differ, with that for the cell with upregulation being higher, scaling
normalisation will reduce normalised counts. Non-upregulated would therefore
also appear downregulated. 

Given the sparsity of scRNA-seq data, the methods are not appropriate.

The method below increases read counts by pooling cells into groups, computing
size factors within each of these groups and scaling them so they are comparable
across clusters. This process is repeated many times, changing pools each time
to collect several size factors for each cell, from which is derived a single
value for that cell.

<!--
see DESeq2 estimateSizeFactorsFromMatrix
see edgeR calcNormFactors
-->

```{r scran_Fig3_Caron}
knitr::include_graphics("../Images/scran_Fig3.png", auto_pdf = TRUE)
```

Clusters of cells are first identified to help form sensible pools of cells.
Scaling factors are then computed.

#### Cluster cells

The table below show the number and size of clusters found:

```{r comp_quickClus_norm_Caron_5hCellPerSpl}
set.seed(100) # clusters with PCA from irlba with approximation
clust <- quickCluster(sce, BPPARAM=bpp) # slow with all cells.
table(clust)
```

#### Compute size factors

```{r calculateSumFactors_norm_Caron_5hCellPerSpl}
sce <- computePooledFactors(sce,
			 clusters = clust,
			 min.mean = 0.1,
			 BPPARAM = bpp)
deconv.sf <- sizeFactors(sce)
summary(deconv.sf)

```

Plot deconvolution size factors against library size factors:

```{r scatter_deconvSf_libSf_colBy_plot_norm_Caron_5hCellPerSpl}

deconvDf <- data.frame(lib.sf, deconv.sf,
			"source_name" = sce$SampleGroup,
			"sum" = sce$sum,
			"mito_content" = sce$subsets_Mito_percent)
```

```{r scatter_deconvSf_libSf_colBy_sourceName_plot_norm_Caron_5hCellPerSpl}
# colour by sample type
sp <- ggplot(deconvDf, aes(x=lib.sf, y=deconv.sf, col=source_name)) +
  geom_point()
sp
```

#### Apply size factors

For each cell, raw counts for genes are divided by the size factor for that cell and log-transformed so downstream analyses focus on genes with strong relative differences. We use `scater::logNormCounts()`.

```{r logNormCounts_norm_Caron_5hCellPerSpl}
sce <- logNormCounts(sce) # adds logcounts
# check list of assays stored:
print(assayNames(sce))
```

#### Save object

```{r sce_write_norm_Caron_5hCellPerSpl}
# write to file
saveRDS(sce, "../Robjects/caron_postDeconv_5hCellPerSpl.Rds")
```

## Exercise 

Exercise: apply the deconvolution normalisation on a single sample: ETV6-RUNX1_1 (aka GSM3872434).

You first load the same object we loaded earlier, then select cells for SampleName 'ETV6-RUNX1_1'. You will then cluster cells, compute and apply size factors.


## Session information

<!--<details>-->
```{r}
sessionInfo()
```
<!--</details>-->
